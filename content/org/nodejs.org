#+ORGA_PUBLISH_KEYWORD: PUBLISHED
#+TODO: DRAFT | PUBLISHED

* PUBLISHED Node.js certification
  CLOSED: [2020-04-23 Sun 19:36]
  Since every single job opportunity for the =unexperienced= developer is either related to Node or Java, and I have done a few Node projects before, I decided to invest my next few weeks into learning Node, JavaScript is not my favorite language, but the ecosystem is huge and there's enough tooling available to make using it an ok experience, for example, I could use TypeScript for a typing system, =Rambda= for a standard library, and Babel for TCO.

  Because I'm mainly learning this for job opportunities, I decided to start with a more professional goal, instead of just reading a book and doing a test project, my goal will be to work towards this [[https://openjsf.org/certification/][certification]] from the =OpenJS= Foundation.

  That's all, I'll be following [[https://www.nodecertification.com/][this]] nice resource compilation, more documents coming soon, probably one for each topic I get my hands on, I don't think I'll try to get certified right after finishing this tho, 300 USD ~monkaS~ is quite expensive and I rather study a little bit more instead of risking throwing this much money await, also because I never really write in english outside of chat rooms and tweets, I'm really looking forward to this! :)

* PUBLISHED Node.js Streams
CLOSED: [2020-04-23 Sun 19:36]
This is the first topic recommend by the [[https://www.nodecertification.com/][node certification guide]], I really like using streams but the Node api is bit cumbersome compared to my previous experiences. The api provides two main classes, ~Writable~ and ~Redable~, there's also ~Duplex~ that just inherits from both of them and ~Transform~ which is just a special form of ~Duplex~ that facilitates applying functions to streams.
#+begin_src js
const { Writable, Redable, Duplex, Transform } = require("stream")

const outStream = new Writable({
  write(chunk, encoding, callback) {
    console.log(chunk.toString())
    callback()
  },
})

const inStream = new Readable({
  read(size) {
    this.push(String.fromCharCode(this.currentCharCode++))
    if (this.currentCharCode > 90) {
      this.push(null)
    }
  },
})

const inoutStream = new Duplex({
  write(chunk, encoding, callback) {
    console.log(chunk.toString())
    callback()
  },

  read(size) {
    this.push(String.fromCharCode(this.currentCharCode++))
    if (this.currentCharCode > 90) {
      this.push(null)
    }
  },
})

const upperCaseTr = new Transform({
  transform(chunk, encoding, callback) {
    this.push(chunk.toString().toUpperCase())
    callback()
  },
})
#+end_src

The ~Pipe()~ method on ~Redable~ streams can be used compose them with ~Writable~ streams, but the ~pipeline()~ utility provides a much nicer way of doing this.
#+begin_src js
a.pipe(read).pipe(duplex).pipe(write)

pipeline(read, duplex, write, err => {})
#+end_src


Streams, like every javascript api, comes with a few event handlers
#+begin_src js
readable.on("data", chunk => {
  writable.write(chunk)
})

readable.on("end", () => {
  writable.end()
})
#+end_src

~ObjectMode~ is an unexpected cool property that let's you mark your stream output/input type as an ~Object~ instead of ~Buffer~, which is the default.
#+begin_src js
const arrayToObject = new Transform({
  readableObjectMode: true,
  writableObjectMode: true,
  transform(chunk, encoding, callback) {
    const obj = {}
    for (let i = 0; i < chunk.length; i += 2) {
      obj[chunk[i]] = chunk[i + 1]
    }
    this.push(obj)
    callback()
  },
})
#+end_src
the ~chunk~ argument in any stream with ~writableObjectMode: true~ will be an ~Object~ :)

A lot of Node core libraries implement the ~stream~ api, so using it feels pretty natural. Thanks to [[https://jscomplete.com/learn/node-beyond-basics/node-streams][jscomplete]] and [[https://heynode.com/tutorial/what-stream][heynode]] for clear and well structure resources.
